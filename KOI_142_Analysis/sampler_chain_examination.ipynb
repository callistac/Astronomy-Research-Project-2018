{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KOI-142 Analysis\n",
    "\n",
    "__If you make use of this code, please cite Christ, C. N., Montet, B. T., & Fabrycky, D. C. 2018, arXiv:1810.02826__\n",
    "\n",
    "- The following code is used to determine how much TESS will improve our measurements of KOI-142 (Kepler-88)\n",
    "\n",
    "- First we must find posterior distribution of parameters with Kepler data only\n",
    "\n",
    "- Then we must find posterior distribution of parameters with Kepler and a theoretical TESS data point\n",
    "\n",
    "- We can compare the two posteriors to see how much TESS will improve our measurements of KOI-142\n",
    "\n",
    "We use TTVFast for this analysis: Deck, Agol, Holman & Nesvorny, 2014,  ApJ, 787, 132, arXiv:1403.1895\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import scipy.optimize as op\n",
    "import os\n",
    "import emcee\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing variables\n",
    "ndim, nwalkers = 13, 150 \n",
    "g_value = 0.000295994511\n",
    "M_star = 0.956\n",
    "\n",
    "G_guess = 0.000295994511\n",
    "Mstar_guess = 0.956\n",
    "M1_guess = 4.34568221e-05\n",
    "P1_guess = 10.915996767 \n",
    "E1_guess = 0.056137334 \n",
    "i1_guess = 89.116000000\n",
    "LongNode1_guess = 0.000000000 \n",
    "W1_guess = -179.794778327+360\n",
    "mean1_guess = 261.169991641\n",
    "M2_guess = 6.113274916e-04\n",
    "P2_guess = 22.267768543 \n",
    "E2_guess = 0.056964888 \n",
    "i2_guess = 85.666179336\n",
    "LongNode2_guess = -0.583597905+360 \n",
    "W2_guess = 0.081068179 \n",
    "mean2_guess = 335.896661714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing arrays\n",
    "tot_transit = np.zeros((355, 10000))\n",
    "mean_transit = np.zeros(355)\n",
    "stdeviation_transit = np.zeros(355)\n",
    "chi_squared = np.zeros((1, 120))\n",
    "miss_epoch = np.array([4, 10, 21, 24, 55, 56, 86, 91, 95, 107, 108, 118, 120, 124]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in KOI-142 Kepler data\n",
    "txt_file = np.loadtxt(\"./c_version/142_TTVs.txt\")\n",
    "TOT = txt_file[:, 1]\n",
    "obs_times = txt_file[:, 2] + txt_file[:, 3] / 1440.0\n",
    "error =  txt_file[:,4] / 1440.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing variables to solve for chi squared in transit duration\n",
    "R_star_AU = 0.961*(1/214.9394693836)\n",
    "delta = 0.039\n",
    "obs_times_dur = 3.28 \n",
    "error_dur = 0.185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal is to find the posterior distribution (and best fit values) of the parameters for KOI-142 with all Kepler data\n",
    "#*Note* Same process was done in Nesvorny et al. (2013), but they did not post their posteriors and so we redid their analysis with all Kepler data\n",
    "\n",
    "'''\n",
    "Likelihood function that will be used for MCMC analysis (chi squared between observed and predicted values by TTVFast)\n",
    "input: \n",
    "    theta (parameter values we are looking to alter) \n",
    "    G_VAL and Mstar (additional, unchanging parameters)\n",
    "    TESS (False- do not include a hypothetical TESS data point, True-include TESS info)\n",
    "output: \n",
    "    function will return a chi squared value for a given set of initial parameters\n",
    "'''\n",
    "def likelihood(theta, G_VAL, Mstar, TESS):\n",
    "    Mpb, Periodb, Eb, Ib, Wb, Meanb, Mpc, Periodc, Ec, Ic, Wc, Longnodec, Meanc = theta\n",
    "    Longnodeb = 0.0\n",
    "    #creating/writing .in file\n",
    "    filename = (\"/Users/Callista/Documents/GitHub/infiles/TTVs0.in\")\n",
    "    infile = open(filename, 'w')\n",
    "    infile.write(\"%.11f\\n%.11f\\n%.11f\\n\" % (G_VAL, Mstar, Mpb))\n",
    "    infile.write(\"%.11f %.11f %.11f %.11f %.11f %.11f\\n\" % (Periodb, Eb, Ib, Longnodeb, Wb, Meanb))\n",
    "    infile.write(\"%.11f\\n\" % Mpc)\n",
    "    infile.write(\"%.11f %.11f %.11f %.11f %.11f %.11f\\n\" % (Periodc, Ec, Ic, Longnodec, Wc, Meanc))\n",
    "    infile.close()\n",
    "\n",
    "    #creating/writing setup file\n",
    "    setupfilename = (\"/Users/Callista/Documents/Github/setupfiles/new_setupfile0\")\n",
    "    new_setupfile = open(setupfilename, 'w')\n",
    "    new_setupfile.write(\"%s\\n %.8f\\n %.3f\\n %d\\n %d\\n %d\\n\" % (filename, 54.675215, 0.54, 3950, 2, 0))\n",
    "    new_setupfile.close()\n",
    "    os.system((\"./run_TTVFast\" + \" \" + setupfilename + \" /Users/Callista/Documents/Github/KOI142_files/final_files0\" + \" RV_file RV_out\"))\n",
    "\n",
    "    tmp_array = np.loadtxt(\"/Users/Callista/Documents/Github/KOI142_files/final_files0\")\n",
    "    planet = tmp_array[:,0]\n",
    "    epoch = tmp_array[:,1]\n",
    "    time = tmp_array[:,2]\n",
    "    Vsky = tmp_array[:, 4]\n",
    "\n",
    "    planet_1 = planet[planet == 0]\n",
    "    epoch_1 = epoch[planet == 0]\n",
    "    time_1 = time[planet == 0]\n",
    "    Vsky_1 = Vsky[planet == 0]\n",
    "    time_1 += 0./1440\n",
    "\n",
    "    #finding chi-squared values\n",
    "    if time_1[0] < 60:\n",
    "        slice_time = time_1[1:]\n",
    "        epoch_1 = np.delete(epoch_1, miss_epoch)\n",
    "        time_1 = np.delete(slice_time, miss_epoch)\n",
    "        chi_squared[i, :] = ((time_1[:120] - obs_times[1:])/ (error[1:]))**2\n",
    "        chi2_tess = 0\n",
    "        if (TESS == True):\n",
    "          #the numbers in the following line were obtained from the TESS_transit_uncert.py file\n",
    "          chi2_tess = ((time_1[-12] - 3823.0106513) / 0.01174660432206573)**2 \n",
    "    else:\n",
    "        epoch_1 = np.delete(epoch_1, miss_epoch)\n",
    "        time_1 = np.delete(time_1, miss_epoch)\n",
    "        chi_squared[i, :] = ((time_1[:120] - obs_times[1:]) / (error[1:]))**2\n",
    "        chi2_tess = 0\n",
    "        if (TESS == True):\n",
    "            chi2_tess = ((time_1[-12] - 3823.0106513) / 0.01174660432206573)**2 \n",
    "\n",
    "    #conversions\n",
    "    Ib_rad = Ib * 0.0174533 \n",
    "    Wb_rad = Wb * 0.0174533\n",
    "    \n",
    "    #finding transit duration vals \n",
    "    semi_axis = np.cbrt(Periodb**2 * g_value*M_star/(4*np.pi**2))\n",
    "    b_val = ((semi_axis**2) * (np.cos(Ib_rad))**2 * (1 / R_star_AU**2) * ((1 - Eb**2)/(1 + Eb * np.sin(Wb_rad)))**2)\n",
    "    \n",
    "    if b_val > 1:\n",
    "        return np.inf\n",
    "    \n",
    "    Tdur = ((2 * (1 + delta) * R_star_AU / Vsky_1) * np.sqrt(1 - b_val))\n",
    "\n",
    "    #converting transit duration values to hours and finding chi squared val\n",
    "    Tdur = Tdur[:1]\n",
    "    Tdur_hours = Tdur * (24.0)\n",
    "    chi2_val = ((Tdur_hours - obs_times_dur) / (error_dur))**2\n",
    "      \n",
    "    #summing chi_vals\n",
    "    sum_matrix = np.sum(chi_squared, axis=1)\n",
    "    ind = np.unravel_index(np.argmin(sum_matrix, axis=None), sum_matrix.shape)\n",
    "    return 0.5*(sum_matrix[ind] + chi2_val + chi2_tess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure chi squared values are significantly reduced by end of optimization\n",
    "bnds = ((0, 0.006), (10.90, 10.93), (0, 1), (60, 90), (0, 360), (0, 360), (0, 0.006), (22.20, 22.35), (0, 1), (60, 120), (180, 540), (-180, 180), (0, 360))\n",
    "result = op.minimize(likelihood, [M1_guess, P1_guess, E1_guess, i1_guess,\n",
    "                          W1_guess, mean1_guess, M2_guess, P2_guess, E2_guess, i2_guess, LongNode2_guess,\n",
    "                          W2_guess, mean2_guess], args=(g_value, M_star, False), method=\"L-BFGS-B\", bounds= bnds)\n",
    "\n",
    "M1, P1, E1, I1, W1, Mean1, M2, P2, E2, I2, Longnode2, W2, Mean2 = result[\"x\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Defining a prior for the total probability function\n",
    "'''\n",
    "def prior(theta):\n",
    "    Mpb, Periodb, Eb, Ib, Wb, Meanb, Mpc, Periodc, Ec, Ic, Wc, Longnodec, Meanc = theta\n",
    "    #force range to be above or below 90 for inclination\n",
    "    if ((0 < Mpb < 0.006) and (10.90 < Periodb < 10.93) and (0 < Eb < 1) and \n",
    "        (60 < Ib < 90) and (0 < Wb < 360) and (0 < Meanb < 360) and (0 < Mpc < 0.006) and \n",
    "        (22.20 < Periodc < 22.35) and (0 < Ec < 1) and (60 < Ic < 120) and (180 < Wc < 540) and (-180 < Longnodec < 180)\n",
    "        and (0 < Meanc < 360)): \n",
    "            return 0.0\n",
    "    else:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Defining a total probability function \n",
    "'''\n",
    "def tot_prob(theta, G_VAL, Mstar, TESS):\n",
    "    lp = prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return lp + -1*likelihood(theta, G_VAL, Mstar, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initalizing walkers into a tiny Gaussian ball around the maximum likelihood parameters\n",
    "ndim, nwalkers = 13, 150 \n",
    "pos = [result[\"x\"] + 0.5*np.array((1e-5, 1e-4, 1e-4, 1, 1, 1, 1e-5, 1e-3, 2.5e-3, 3, 2, 1, 1e-1))*np.random.randn(ndim) for i in range(nwalkers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, tot_prob, args=(g_value, M_star, False))\n",
    "sampler.run_mcmc(pos, 10000)\n",
    "np.save(\"sampler_chains1\", sampler.chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if chains are burnt in (using eccentricity as an example)\n",
    "plt.plot(sampler.chain[:, :, 2].T, 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chains for some parameters do not appear to be fully burnt in, so rerun MCMC from where run_mcmc left off the last time it executed\n",
    "sampler.run_mcmc(None, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.chain[:, 5000:, :].reshape((-1, ndim))\n",
    "np.save(\"sampler_chains2\", sampler.chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find posterior distribution for KOI-142 parameters with Kepler AND a hypothetical TESS data point (arg=True)\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, tot_prob, args=(g_value, M_star, True))\n",
    "sampler.run_mcmc(pos, 10000)\n",
    "np.save(\"sampler_chains_tess\", sampler.chain)\n",
    "sampler.run_mcmc(None, 10000)\n",
    "samples_tess = sampler.chain[:, 5000:, :].reshape((-1, ndim))\n",
    "np.save(\"sampler_chains2_tess\", sampler.chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finding the best fit parameters and their 1sigma uncertainties \n",
    "Input:\n",
    "  data, whether we are using only Kepler data or Kepler AND TESS data\n",
    "Output:\n",
    "  \n",
    "'''\n",
    "def best_fit_errors(data, width_uncert):\n",
    "    xx = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(data, [15.8, 50, 84.2], axis=0)))\n",
    "  params_lst = ['mass1', 'period1', 'e1', 'I1', 'w1', 'Mean1', 'mass2', 'period2', 'e2', 'I2', 'Longnode2', 'w2', 'Mean2']\n",
    "  for nn in range(13):\n",
    "      print(params_lst[nn], xx[nn])\n",
    "      #finding the width of the 68% confidence interval (adding uncertainties) for KOI-142 transits\n",
    "      width_uncert[nn] = xx[nn][1] + xx[nn][2]\n",
    "  return width_uncert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
