{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESS Transit Uncertainty Calculation\n",
    "\n",
    "The following code predicts the TESS transit uncertainty in July 2019 using simulated transit techniques\n",
    "\n",
    "The predicted transit uncertainty for TESS from this file is used in the likelihood function in KOI_142_Analysis.ipynb\n",
    "\n",
    "Code makes use of Batman (Kreidberg, L. 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import batman \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import newton_krylov\n",
    "\n",
    "g_value = 0.000295994511\n",
    "M_star = 0.956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing arrays\n",
    "#sampling a data point every 30 mins (but stacking transits since KOI-142 will be observed 3 times in 30 mins due to its orbital period)\n",
    "thirty_min_x = np.arange(-0.2, 0.2, 0.02083/3) \n",
    "chi2_array = []\n",
    "t0_array = np.linspace(-0.1, 0.1, 3000) \n",
    "t0_vs_chi2 = np.zeros(shape=(len(t0_array), 2))\n",
    "thirty_min_xy_lst = []\n",
    "new_y_array = []\n",
    "\n",
    "#used for storing information from initial run of batman\n",
    "flux_uncert_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a model lightcurve (using most probable parameters) and creating noisy \"fake\" data points\n",
    "a_axis_au = np.cbrt((10.91657654631031)**2 *g_value*M_star/(4*np.pi**2)) \n",
    "a_axis_stellar_r = a_axis_au*214.93946938362/0.961\n",
    "\n",
    "bat_params = batman.TransitParams()\n",
    "bat_params.t0 = 0.\n",
    "bat_params.per = 10.91657654631031\n",
    "bat_params.rp = 0.0403\n",
    "bat_params.a = a_axis_stellar_r\n",
    "bat_params.inc = 88.42792792493891\n",
    "bat_params.ecc = 0.05565288586927001\n",
    "bat_params.w = 179.04619342089515\n",
    "bat_params.u = [0.2075, 0.3785]\n",
    "bat_params.limb_dark = \"quadratic\"\n",
    "\n",
    "t_samples = np.linspace(-0.2, 0.2, 1300)\n",
    "\n",
    "b_model = batman.TransitModel(bat_params, thirty_min_x, supersample_factor=7, exp_time=0.02083)\n",
    "flux = b_model.light_curve(bat_params)\n",
    "\n",
    "#finding chi squared between \"observed\" flux and calculated flux\n",
    "np.random.seed(6)\n",
    "flux_uncert = np.random.normal(0, np.sqrt(2)*1500e-6, len(thirty_min_x)) #1500 comes from Sullivan et al. paper\n",
    "flux_uncert_array.append(flux_uncert)\n",
    "new_y = flux + flux_uncert\n",
    "new_y_array.append(new_y)\n",
    "residuals = (flux - new_y)**2\n",
    "chi2 = residuals / (np.sqrt(2)*1500e-6)**2 \n",
    "print(\"chi2\", chi2)\n",
    "chi2_array.append(chi2)\n",
    "    \n",
    "plt.plot(thirty_min_x, new_y, 'g.')\n",
    "        \n",
    "#print(0.5*np.sum(chi2_array))\n",
    "#print(np.exp(-0.5*np.sum(chi2_array)))\n",
    "\n",
    "#reinitalizing arrays to be empty\n",
    "thirty_min_xy_lst = []\n",
    "chi2_array = []\n",
    "\n",
    "plt.plot(thirty_min_x, flux)\n",
    "plt.xlabel(\"Time from central transit (days)\")\n",
    "plt.ylabel(\"Relative flux\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altering the t0 parameter in batman to alter transit times \n",
    "#Finds chi squared value between the previous cell's data points and the calculated flux for each specific t0\n",
    "#outputs a grid of t0 vs chi2 values \n",
    "for time in range(len(t0_array)):\n",
    "    print(\"time\", t0_array[time])\n",
    "    a_axis_au = np.cbrt((10.91657654631031)**2 *g_value*M_star/(4*np.pi**2)) \n",
    "    a_axis_stellar_r = a_axis_au*214.93946938362/0.961\n",
    "\n",
    "    bat_params = batman.TransitParams()\n",
    "    bat_params.t0 = t0_array[time]\n",
    "    bat_params.per = 10.91657654631031\n",
    "    bat_params.rp = 0.0403\n",
    "    bat_params.a = a_axis_stellar_r\n",
    "    bat_params.inc = 88.42792792493891\n",
    "    bat_params.ecc = 0.05565288586927001\n",
    "    bat_params.w = 179.04619342089515\n",
    "    bat_params.u = [0.2075, 0.3785]\n",
    "    bat_params.limb_dark = \"quadratic\"\n",
    "\n",
    "    t_samples = np.linspace(-0.1, 0.1, 3000) \n",
    "\n",
    "    b_model = batman.TransitModel(bat_params, thirty_min_x, supersample_factor=7, exp_time=0.02083) \n",
    "    flux = b_model.light_curve(bat_params)\n",
    "\n",
    "    residuals = (flux - new_y_array)**2\n",
    "    chi2 = residuals / (np.sqrt(2)*1500e-6)**2  \n",
    "    chi2_array.append(chi2)\n",
    "    plt.plot(thirty_min_x, new_y_array[0], 'g.')\n",
    "            \n",
    "    t0_vs_chi2[time, 0] = t0_array[time]\n",
    "    t0_vs_chi2[time, 1] = np.sum(chi2_array)\n",
    "\n",
    "    #reinitalizing arrays to be empty\n",
    "    thirty_min_xy_lst = []\n",
    "    chi2_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds the minimum chi2 value, subtracts that from the entire column to find chi2 values relative to the best chi2 value\n",
    "#converts those relative chi2 values to likelihoods (-0.5 and exponentiate)\n",
    "#normalizes those likelihood values\n",
    "likelihood_array = np.zeros(shape=(len(t0_vs_chi2)))\n",
    "transit_time = np.zeros(shape=(len(t0_vs_chi2)))\n",
    "normalized_likelihood = np.zeros(shape=(len(t0_vs_chi2)))\n",
    "\n",
    "for k in range (len(t0_vs_chi2)):\n",
    "    #subtracting off the best value for chi2 so parabola has a min at zero and turning it into a likelihood\n",
    "    likelihood_array[k] = (np.exp(-0.5*(t0_vs_chi2[k][1] - (np.min(t0_vs_chi2, axis=0))[1])))\n",
    "    transit_time[k] = t0_vs_chi2[k][0]\n",
    "\n",
    "#finding the norm of the likelihoods \n",
    "likelihood_array /= np.sum(likelihood_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "subtracting off the first 16th and 84th percentile\n",
    "finding the transit time values where the y value (likelihoods) crosses zero\n",
    "the standard deviation is half of t_84 - t_16\n",
    "'''\n",
    "neg_val1 = 0.0\n",
    "neg_val2 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the cumulative sum of the likelihood array\n",
    "final_likelihood = np.cumsum(likelihood_array)\n",
    "print(final_likelihood[630:660])\n",
    "\n",
    "first_dev = final_likelihood - 0.158 \n",
    "second_dev = final_likelihood - 0.842\n",
    "\n",
    "print(first_dev)\n",
    "\n",
    "first_func = interp1d(transit_time, first_dev)\n",
    "\n",
    "plt.plot(first_func.x, first_func.y, '-')\n",
    "plt.show()\n",
    "\n",
    "second_func = interp1d(transit_time, second_dev)\n",
    "\n",
    "#finding where the likelihood values cross zero at 16th percentile\n",
    "for index1 in range(len(first_dev)):\n",
    "    if first_dev[index1] < 0:\n",
    "        neg_val1 = first_dev[index1]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "y1 = neg_val1\n",
    "y2 = first_dev[index1]\n",
    "\n",
    "x1 = transit_time[index1-1]\n",
    "x2 = transit_time[index1]\n",
    "\n",
    "#solving for the transit time where likelihoods cross zero at 16th percentile\n",
    "\n",
    "slope1 = (y1 - y2) / (x1 - x2)\n",
    "t_16 = -1*((y1 - 0) / slope1) + x1 \n",
    "print(\"t_16\", t_16)\n",
    "\n",
    "\n",
    "#finding where the likelihood values cross zero at the 84th percentile\n",
    "for index2 in range(len(second_dev)):\n",
    "    if second_dev[index2] < 0:\n",
    "        neg_val2 = second_dev[index2]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "y84_1 = neg_val2\n",
    "y84_2 = second_dev[index2]\n",
    "x84_1 = transit_time[index2-1]\n",
    "x84_2 = transit_time[index2]\n",
    "\n",
    "#solving for the transit time where likelihoods cross zero at the 84th percentile\n",
    "slope2 = (y84_1 - y84_2) / (x84_1 - x84_2)\n",
    "t_84 = -1*((y84_1 - 0) / slope2) + x84_1\n",
    "print(\"t_84\", t_84)\n",
    "\n",
    "#finding the approximate TESS uncertainty for 2019, used in likelihood func. in KOI_142_Analysis.ipynb\n",
    "std_dev_final = 0.5*(t_84 - t_16)\n",
    "print(std_dev_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
